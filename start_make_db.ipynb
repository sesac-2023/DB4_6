{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ※ AWS는 적재, 조회 등에 비용이 발생하니 최종 코드가 아닌 한 local에서 TEST!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aws 계정 로그인 셀\n",
    "import pymysql\n",
    "import pandas as pd # 불요. 출력값 보기용.\n",
    "\n",
    "# 계정 정보 파일에서 필요 인자 딕셔너리로 생성\n",
    "with open('secret_local_db.config') as f:\n",
    "    res = dict(map(lambda x: x.replace('\\n','').split('='), f.readlines()))\n",
    "    for i, v in res.items():\n",
    "        if v.isdigit(): res[i] = int(v)\n",
    "# 로그인 위한 인자명 출력\n",
    "print(res.keys())\n",
    "# 딕셔너리 언패킹하여 인자 값 할당 후 서버 연동\n",
    "remote = pymysql.connect(**res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# db 및 유저 생성\n",
    "\n",
    "# with로 여는 것은 cursor가 여러 개 열리는 것을 예방하기 위함.\n",
    "with remote.cursor() as cur:\n",
    "    # db명 설정 및 생성\n",
    "    dbname = 'db4_6'\n",
    "    # cur.execute(f'create database {dbname}')\n",
    "    cur.execute('show databases')\n",
    "    # fetchall(): 출력문 전체 가져오기\n",
    "    # print(cur.fetchall())\n",
    "    print(f'{\"  show databases  \":=^80}')\n",
    "    print(pd.DataFrame([_ for _ in cur.fetchall()], columns=['database_name']))\n",
    "    \n",
    "    # # user 생성 및 권한 지정\n",
    "    # username = 'tmp_01'\n",
    "    # password = 'tmp_1234'   # 연습용이 아닌 실제 생성 user는 secret 파일을 통해 인자 입력 필요\n",
    "    # cur.execute('use mysql')\n",
    "    # # user 생성, %는 외부 접속 사용자라는 의미.\n",
    "    # cur.execute(f'create user \\'{username}\\'@\\'%\\' identified by \\'{password}\\'')\n",
    "    # # 특정 db 권한 전부(*) 부여\n",
    "    # cur.execute(f'grant all on {dbname}.* to \\'{username}\\'@\\'%\\'')\n",
    "    # # 특정 user 권한 확인\n",
    "    # cur.execute(f'show grants for \\'{username}\\'@\\'%\\'')\n",
    "    # # print(cur.fetchall())\n",
    "    # print(f'''{\"  show grants for '{username}'@'%'  \":=^80}''')\n",
    "    # print(pd.DataFrame([_ for _ in cur.fetchall()], columns=['grant users']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # db 및 유저 삭제\n",
    "\n",
    "# with remote.cursor() as cur:\n",
    "#     # user 권한 제거 및 user 삭제\n",
    "#     username = 'tmp_01'\n",
    "#     cur.execute('use mysql')\n",
    "#     # user 테이블의 host, user 컬럼 조회\n",
    "#     cur.execute('select host, user from user')\n",
    "#     # print(cur.fetchall())\n",
    "#     print(f'{\"  select host, user from user  \":=^80}')\n",
    "#     print(pd.DataFrame([_ for _ in cur.fetchall()], columns=['host', 'user']))\n",
    "    \n",
    "#     # 특정 db 권한 전부(*) 제거\n",
    "#     cur.execute(f'revoke all on {dbname}.* from \\'{username}\\'@\\'%\\'')\n",
    "#     # 특정 user 권한 확인\n",
    "#     cur.execute(f'show grants for \\'{username}\\'@\\'%\\'')\n",
    "#     # print(cur.fetchall())\n",
    "#     print(f'''{\"  show grants for '{username}'@'%'  \":=^80}''')\n",
    "#     print(pd.DataFrame([_ for _ in cur.fetchall()]))\n",
    "\n",
    "#     # 특정 user 삭제\n",
    "#     cur.execute(f'drop user \\'{username}\\'@\\'%\\'')\n",
    "#     # user 제거 확인\n",
    "#     cur.execute('select host, user from user')\n",
    "#     # print(cur.fetchall())\n",
    "#     print(f'{\"  select host, user from user  \":=^80}')\n",
    "#     print(pd.DataFrame([_ for _ in cur.fetchall()], columns=['host', 'user']))\n",
    "\n",
    "\n",
    "#     # db 삭제\n",
    "#     cur.execute('show databases')\n",
    "#     # print(cur.fetchall())\n",
    "#     print(f'{\"  show databases  \":=^80}')\n",
    "#     print(pd.DataFrame([_ for _ in cur.fetchall()], columns=['database_name']))\n",
    "    \n",
    "#     dbname = 'db4_6'\n",
    "#     cur.execute(f'drop database {dbname}')\n",
    "#     # db 삭제 확인\n",
    "#     cur.execute('show databases')\n",
    "#     # print(cur.fetchall())\n",
    "#     print(f'{\"  show databases  \":=^80}')\n",
    "#     print(pd.DataFrame([_ for _ in cur.fetchall()], columns=['database_name']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with remote.cursor() as cur:\n",
    "    cur.execute('show tables')\n",
    "    print(f'{\"  show tables  \":=^80}')\n",
    "    print(pd.DataFrame([_ for _ in cur.fetchall()], columns=['tables']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_file = 'Elementary_ERD.sql'\n",
    "# sql_file = 'Elementary_ERD.txt'\n",
    "\n",
    "with remote.cursor() as cur:\n",
    "    # 파일에서 '\\ufeff'가 읽힐 경우 encoding하거나 replace로 제거\n",
    "    with open(sql_file, 'r', encoding='utf-8-sig') as f :\n",
    "        # split(';')이기에 마지막에 ['']가 존재하여 [:-1]로 슬라이싱\n",
    "        commands = f.read().split(';')[:-1]\n",
    "    for command in commands:\n",
    "        cur.execute(command.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with remote.cursor() as cur:\n",
    "    # category 불러오기\n",
    "    try:\n",
    "        with open('category.json', 'r') as f:\n",
    "            category = json.load(f)\n",
    "    except:\n",
    "        print(\"category.json don't exist or path is worng.\")\n",
    "\n",
    "    # category 확인 및 적재\n",
    "    done_list = []\n",
    "    error_list = []\n",
    "    try:\n",
    "        cur.execute('select count(*) from category')\n",
    "        if cur.fetchall()[0][0]==145:\n",
    "            print('='*50)\n",
    "            print('already all record is loaded on CATEGORY table')\n",
    "            pass\n",
    "        else:\n",
    "            for platfrom in category.keys():\n",
    "                for cat_1 in category[platfrom].keys():\n",
    "                    for name, id in category[platfrom][cat_1].items():\n",
    "                        try:\n",
    "                            cur.execute(f\"insert into category values({id}, '{cat_1}','{name}', '{platfrom}')\")\n",
    "                            done_list.append([id, cat_1, name, platfrom])\n",
    "                        except:\n",
    "                            error_list.append([id, cat_1, name, platfrom])\n",
    "                            print(f\"already values({id}, '{cat_1}','{name}', '{platfrom}' exist\")\n",
    "            print('='*50)\n",
    "            print(f'done_tasl: {len(done_list)}, error_task: {len(error_list)}')\n",
    "    except:\n",
    "        print(\"make tables first!\")\n",
    "\n",
    "# DML은 별도 commit 필요!\n",
    "remote.commit()\n",
    "print('task is done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# naver news 전처리\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "with open('secret_naver_news_data.pkl', 'rb') as f:\n",
    "    df_naver = pd.DataFrame(pickle.load(f))\n",
    "\n",
    "ch_df = df_naver[df_naver[1].apply(lambda x: False if x.find('@')==-1 else True)][1].str.split('@').str[0].apply(lambda x: ' '.join(re.split(r'[(, )]', x)[:-1]))\n",
    "df_naver.loc[ch_df.index,1] = ch_df\n",
    "df_naver[9] = df_naver[9].apply(lambda x: ' '.join([_ for _ in x if '\\t' not in _ and '\\n' not in _]))\n",
    "df_naver[12] = '세계'\n",
    "df_naver = df_naver[[12,5,8,2,0,1,3,4,9,11,7]]\n",
    "df_columns = ['cat1_name', 'cat2_name', 'platform_name', 'title', 'press', 'writer', 'date_upload', 'date_fix', 'content', 'sticker', 'url']\n",
    "df_naver.columns = df_columns\n",
    "\n",
    "# 결측값은 모두 None으로 변경\n",
    "df_naver.loc[df_naver[df_naver['date_fix']=='null'].index, 'date_fix'] = None\n",
    "df_naver.loc[df_naver[df_naver['writer']=='null'].index, 'writer'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# naver news 전처리\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "with open('secret_daum_news_data.pkl', 'rb') as f:\n",
    "    df_daum = pd.DataFrame(pickle.load(f))\n",
    "\n",
    "df_columns = ['cat1_name', 'cat2_name', 'platform_name', 'title', 'press', 'writer', 'date_upload', 'date_fix', 'content', 'sticker', 'url']\n",
    "classified = {1411: '아시아/대양주', 1412: '미국/아메리카', 1413: '유럽', 1414: '중동/아프리카', 1415: '국제일반', 1416: '영어뉴스', 1417: '해외화제', 1418: '일본', 1419: '중국'}\n",
    "\n",
    "df_daum[11] = '국제'\n",
    "df_daum = df_daum[[11,6,8,2,0,1,3,4,9,10,7]]\n",
    "df_daum[6] = df_daum[6].apply(lambda x: classified.get(int(x)))\n",
    "df_daum[1] = df_daum[1].apply(lambda x: None if str(x).find('입력 <span')==0 else x)\n",
    "df_daum[3] = [datetime(int(__[0]), int(__[1]), int(__[2]), int(__[3].split(':')[0]), int(__[3].split(':')[1])).strftime('%Y-%m-%d %H:%M:%S') for __ in [_.split('. ') for _ in df_daum[3]]]\n",
    "df_daum[4] = None\n",
    "df_daum.columns = df_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column 이름 일치 확인\n",
    "def insert_news(remote, df):\n",
    "    df_columns = ['cat1_name', 'cat2_name', 'platform_name', 'title', 'press', 'writer', 'date_upload', 'date_fix', 'content', 'sticker', 'url']\n",
    "    if sum(~(df_columns==df.columns)):\n",
    "        raise Exception(f\"columns' name dont matched!!\\nmake columns' name like {df_columns}\")\n",
    "\n",
    "    # platform_name 변환 및 cat2_id 할당\n",
    "    with open('category.json', 'r') as f:\n",
    "                SUB_CATEGORY_DICT = json.load(f)\n",
    "                \n",
    "    df['platform_name'] = [platform if platform in (\"네이버\", \"다음\") else \"네이버\" if platform.upper()==\"NAVER\" else \"다음\" if platform.upper()==\"DAUM\" else None for platform in df['platform_name']]\n",
    "    if df['platform_name'].isna().any():\n",
    "        raise Exception('some platform_name rows wrong!!')\n",
    "    df['cat2_id'] = [SUB_CATEGORY_DICT[_[0]][_[1]][_[2]] for _ in df[['platform_name', 'cat1_name', 'cat2_name']].values]\n",
    "    df_columns = ['cat2_id']+df_columns\n",
    "    df = df[df_columns]\n",
    "    df.drop(columns=['cat1_name', 'cat2_name', 'platform_name'], inplace=True)\n",
    "\n",
    "    # sticker json 따옴표 변경\n",
    "    if not sum(df['sticker'].apply(str).str.count('\"')):\n",
    "        df['sticker'] = df['sticker'].apply(json.dumps)\n",
    "\n",
    "    with remote.cursor() as cur:\n",
    "        my_query = \"insert ignore into NEWS(cat2_id, title, press, writer, date_upload, date_fix, content, sticker, url) values(%s, %s, %s, %s, %s, %s, %s, %s, %s)\"\n",
    "        cur.executemany(my_query, df.values.tolist())\n",
    "    remote.commit()\n",
    "insert_news(remote, df_daum)\n",
    "insert_news(remote, df_naver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# naver comment 전처리\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "with open('secret_naver_news_data.pkl', 'rb') as f:\n",
    "    df_naver = pd.DataFrame(pickle.load(f))\n",
    "df = df_naver[[10,7]]\n",
    "df.columns = ['comment', 'url']\n",
    "df = df[df.comment.apply(len)!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_list = []\n",
    "with remote.cursor() as cur:\n",
    "    my_query = \"select id, url from news where url=%s\"\n",
    "    for v in df['url'].values:\n",
    "        cur.execute(my_query, v)\n",
    "        tmp_list.extend(cur.fetchall())\n",
    "\n",
    "tmp_list = pd.DataFrame(tmp_list, columns=['news_id', 'url'])\n",
    "df = pd.merge(df, tmp_list, 'left', 'url').explode('comment').reset_index(drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trash, df['comment'], df['user_id'], df['user_name'], df['date_upload'], df['date_fix'], df['good_cnt'], df['bad_cnt'] = zip(*df.comment.values)\n",
    "del trash\n",
    "df['date_upload'] =  df['date_upload'].str.split('+').str[0]\n",
    "df['date_upload'] = [' '.join(date__[:-5].split('T')) for date__ in df['date_upload']]\n",
    "df['date_fix'] = [' '.join(date__[:-5].split('T')) for date__ in df['date_fix']]\n",
    "df = df[~df.user_id.isna()].reset_index(drop=True)\n",
    "df_columns = ['news_id', 'user_id', 'user_name', 'comment', 'date_upload', 'date_fix', 'good_cnt', 'bad_cnt']\n",
    "df = df[df_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df = df.groupby(['user_id', 'user_name']).count().reset_index()[['user_id', 'user_name']]\n",
    "with remote.cursor() as cur:\n",
    "    my_query = \"insert ignore into USER(user_id, user_name) values(%s, %s)\"\n",
    "    cur.executemany(my_query, user_df.values.tolist())\n",
    "remote.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get user_id\n",
    "tmp_list = []\n",
    "with remote.cursor() as cur:\n",
    "    my_query = \"select id, user_id from user where user_id=%s\"\n",
    "    for v in user_df.user_id.values:\n",
    "        cur.execute(my_query, v)\n",
    "        tmp_list.extend(cur.fetchall())\n",
    "tmp_list = pd.DataFrame(tmp_list, columns=['id', 'user_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df, tmp_list.drop_duplicates('user_id').reset_index(drop=True), 'left', 'user_id').reset_index(drop=True)\n",
    "df_columns.pop(2)\n",
    "df = df.drop(columns='user_id').rename(columns={'id': 'user_id'})[df_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with remote.cursor() as cur:\n",
    "    my_query = \"insert ignore into COMMENT(news_id, user_id, comment, date_upload, date_fix, good_cnt, bad_cnt) values(%s, %s, %s, %s, %s, %s, %s)\"\n",
    "    cur.executemany(my_query, df.values.tolist())\n",
    "remote.commit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "news",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
